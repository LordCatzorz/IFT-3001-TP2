% !TeX root = ../main.tex
\documentclass[class=article]{standalone}

\begin{document}
\centerline{\Huge \bf Question 1}
\bigskip

\section*{Algorithme 1}

Le temps d'exécution de l'algorithme dépend de la taille de l'instance $n$ 
(nombre d'éléments dans le vecteur d'entrée $A$)
et de la valeur de $k$ générée aléatoirement. 

L'opération de base est le calcul de $i\text{ mod }n$. 
C'est l'opération qui peut être le plus souvent.

Il n'y a pas de pire ou de meilleur cas, 
car l'algorithme ne dépend pas du contenu du vecteur (à l'exception de $n=1$,
où la valeur $A[0]=0$ où la conditionnelle s'exécutera toujours et où $A[0] = 1$ ou elle ne s'exécutera jamais).

Désignons la valeur de $A[0]$ par $a$

La complexité de l'algorithme dans tous les cas est donc la suivante:

\begin{deriv}
    C\pars{n}
    \<=
    \commentaire{Définition de l'algorithme}
    E_a\crochs{E_k\crochs{C\pars{n, k, a}}}
    \<=
    \commentaire{Étendre les espérances}
    \sum\limits_{a} \rho\pars{a} \sum\limits_{k} \rho\pars{k}C\pars{n, k, a}
    \<=
    \commentaire{Valeur de $a$ possible est de $\crochs{0..1}$}
    \sum\limits_{a=0}^{1} \rho\pars{a} \sum\limits_{k} \rho\pars{k}C\pars{n, k, a}
    \<=
    \commentaire{Valeur de $k$ possible est de $\crochs{0..n-1}$}
    \sum\limits_{a=0}^{1} \rho\pars{a} \sum\limits_{k=0}^{n-1} \rho\pars{k}C\pars{n, k, a}
    \<=
    \commentaire{Toutes les possibilités d'avoir une valeur $a$ \\
        sont équiprobables. Donc $\rho{\pars{a} = \frac{1}{2}}$ }
        \sum\limits_{a=0}^{1} \frac{1}{2} \sum\limits_{k=0}^{n-1} \rho\pars{k}C\pars{n, k, a}
    \<=
    \commentaire{Toutes les possibilités d'avoir une valeur $k$ \\
        sont équiprobables. Donc $\rho{\pars{a} = \frac{1}{n}}$ }
    \sum\limits_{a=0}^{1} \frac{1}{2} \sum\limits_{k=0}^{n-1} \frac{1}{n}C\pars{n, k, a}
    \<=
    \commentaire{Mettre en évidence les constantes}
    \frac{1}{2}\frac{1}{n} \sum\limits_{a=0}^{1}\sum\limits_{k=0}^{n-1} C\pars{n, k, a}
    \<=
    \commentaire{Étendre partiellement la sommation de $k$}
    \frac{1}{2}\frac{1}{n} \sum\limits_{a=0}^{1}\pars{C\pars{n, 0, a} + C\pars{n, 1, a} + \sum\limits_{k=2}^{n-1} C\pars{n, k, a}}
    \<=
    \commentaire{Selon le tableau plus bas, $\forall k \geq 2 : C\pars{n, k, a} = 0$}
    \frac{1}{2}\frac{1}{n} \sum\limits_{a=0}^{1}\pars{C\pars{n, 0, a} + C\pars{n, 1, a}}
    \<=
    \commentaire{Étendre la sommation de $a$}
    \frac{1}{2}\frac{1}{n} \pars{C\pars{n, 0, 0} + C\pars{n, 1, 0} + C\pars{n, 0, 1} + C\pars{n, 1, 1}}
    \<=
    \commentaire{Selon le tableau plus bas}
    \frac{1}{2}\frac{1}{n} \pars{ 100n + 0 + 0 + 100n}
    \<=
    \commentaire{Simplification}
    \frac{1}{2}\frac{1}{n} \pars{ 200n}
    \<=
    \commentaire{Simplification}
    \frac{1}{2} \pars{ 200}
    \<=
    \commentaire{Simplification}
    100
    \<\in
    \commentaire{Définition de $\Theta\pars{1}$}
    \Theta\pars{1}
\end{deriv} 

Analysons $C\pars{n, k, a}$

\begin{tabular}{c|c|c|c|c|c}
    \multicolumn{1}{c}{} &
    \multicolumn{5}{|c}{$C(n, k, a)$}\\
    \hline
    $a$ & $C(n, 0, a)$ & $C(n, 1, a)$ & $C(n, 2, a)$ & $C(n, i, a)$ &  $C(n, n, a)$ \\
    \hline
    $a=0$ & $100 \cdot n$ & 0 & 0 & 0 &  0\\
    \hline
    $a=1$ & 0 & $100 \cdot n$ & 0 & 0 &  0
\end{tabular}

\newpage

\section*{Algorithme 2}

Le temps d'exécution de l'algorithme dépend de la taille de l'instance $n$ 
(nombre d'éléments dans le vecteur d'entrée $A$)
et de la valeur de $k$ générée aléatoirement. 

L'opération de base est le calcul de $i\text{ mod }n$.
C'est l'opération qui peut être exécutée le plus souvent.

Il y a un meilleur et un pire cas.

\subsection*{Pire cas}
En pire cas, la valeur à la première position du vecteur $A$ est 0. ($A[0] = 0$)

Alors, nous entrons dans la conditionnelle \lstinline{si - alors}.

La complexité de l'algorithme en pire cas sera donc la suivante:

\begin{deriv}
    C_{worst}\pars{n}
    \<=
    \commentaire{Définition de l'algorithme}
    E_k\crochs{C\pars{n, k}}
    \<=
    \commentaire{Étendre les espérances}
    \sum\limits_{k} \rho\pars{k}C\pars{n, k}
    \<=
    \commentaire{Valeur possible de $k$}
    \sum\limits_{k=0}^{n-1} \rho\pars{k}C\pars{n, k}
    \<=
    \commentaire{Toutes les possibilités d'avoir une valeur de $k$\\
                 sont équiprobables. Donc $\rho\pars{k} = \frac{1}{n}$}
    \sum\limits_{k=0}^{n-1} \frac{1}{n}C\pars{n, k}
    \<=
    \commentaire{Extraction de valeur constante de la sommation}
    \sum\limits_{k=0}^{n-1} \frac{1}{n}C\pars{n, k}
    \<=
    \commentaire{Extraction de valeur constante de la sommation}
    \frac{1}{n}\sum\limits_{k=0}^{n-1} C\pars{n, k}
    \<=
    \commentaire{Définition de $C\pars{n, k}$}
    \frac{1}{n}\sum\limits_{k=0}^{n-1} \sum\limits_{i=1}^{k^2} 1
    \<=
    \commentaire{Règle de sommation}
    \frac{1}{n}\sum\limits_{k=0}^{n-1} \pars{k^2 - 1 + 1} \cdot 1
    \<=
    \commentaire{Simplification}
    \frac{1}{n}\sum\limits_{k=0}^{n-1} k^2
    \<=
    \commentaire{Règle de sommation}
    \frac{1}{n}\frac{\pars{n-1}\pars{n-1+1}\pars{2\pars{n-1}+1}}{6}
    \<=
    \commentaire{Simplification}
    \frac{1}{n}\frac{\pars{n-1}\pars{n}\pars{2n-2+1}}{6}
    \<=
    \commentaire{Simplification}
    \frac{\pars{n-1}\pars{n}\pars{2n-1}}{6n}
    \<=
    \commentaire{Simplification}
    \frac{\pars{n-1}\pars{2n-1}}{6}
    \<=
    \commentaire{Étendre le polynôme}
    \frac{2n^2-3n + 1}{6}
    \<=
    \commentaire{Répartir la fraction}
    \frac{2n^2}{6}-\frac{3n}{6}+\frac{1}{6}
    \<=
    \commentaire{Simplification}
    \frac{n^2}{3}-\frac{n}{2}+\frac{1}{6}
\end{deriv}


\subsubsection*{Calcul de $\BigO$}
\begin{deriv}
    C_{worst}\pars{n}
    \<=
    \commentaire{Définition plus haut}
    \frac{n^2}{3}-\frac{n}{2}+\frac{1}{6}
    \<\leq
    \commentaire{Retirer la soustraction}
    \frac{n^2}{3}+\frac{1}{6}
    \<\in
    \commentaire{Règle du maximum et définition de $\BigO$}
    \BigO\pars{n^2}
\end{deriv}

\subsubsection*{Calcul de $\Omega$}
\begin{deriv}
    C_{worst}\pars{n}
    \<=
    \commentaire{Définition plus haut}
    \frac{n^2}{3}-\frac{n}{2}+\frac{1}{6}
    \<\geq
    \commentaire{Retirer l'addition d'une constante}
    \frac{n^2}{3}-\frac{n}{2}
    \<= 
    \commentaire{Remettre sur un diviseur commun}
    \frac{2n^2}{6}-\frac{3n}{6}
    \<= 
    \commentaire{Mettre en évidence le diviseur.}
    \frac{1}{6}\pars{2n^2-3n}
    \<\geq 
    \commentaire{$\forall n \geq 3$}
    \frac{1}{6}\pars{2n^2-n^2}
    \<=
    \commentaire{Simplification}
    \frac{1}{6}\pars{n^2}
    \<\in
    \commentaire{Définition de $\Omega$}
    \Omega\pars{n^2}
\end{deriv}

\subsubsection*{Définition de $\Theta$}
Puisque $C_{worst}\pars{n} \in \Omega\pars{n^2}$ et $C_{worst}\pars{n} \in \BigO\pars{n^2}$,
$C_{worst}\pars{n} \in \Theta\pars{n^2}$

\subsection*{Meilleur cas}

En meilleur cas, la valeur à la première position du vecteur $A$ est 1. ($A[0] = 1$)

Alors, nous sautons complètement la conditionnelle \lstinline{si - alors}.

Puisque l'opération de base n'est jamais exécutée,
la complexité de l'algorithme en meilleur cas sera donc la suivante:
$C_{best}\pars{n} = 0 \in \Theta\pars{1}$


\subsection*{Cas moyen}

En cas moyen, il faut calculer la moyenne sur toutes les instances de taille $n$.

Définition $a = A[0]$

La complexité de l'algorithme en cas moyen sera donc la suivante:
\begin{deriv}
    C_{avg}\pars{n}
    \<=
    \commentaire{Définition de l'algorithme}
    E_{a}E_{k}\crochs{C\pars{n, k, a}}
    \<=
    \commentaire{Étendre l'espérance de $a$}
    \sum\limits_a \rho\pars{a}E_{k}\crochs{C\pars{n, k, a}}
    \<=
    \commentaire{Valeurs possibles de $a$}
    \sum\limits_{a=0}^1 \rho\pars{a} E_{k}\crochs{C\pars{n, k, a}}
    \<=
    \commentaire{La probabilité d'avoir $a = 0$ est de $\frac{1}{n}.$\\
                 Donc la probabilité d'avoir $a \neq 0$ est de $\frac{n-1}{n}$}
    \frac{1}{n} E_{k}\crochs{C\pars{n, k, 0}} + \frac{n-1}{n} E_{k}\crochs{C\pars{n, k, 1}}
    \<=
    \commentaire{$C_{worst}\pars{n} = E_{k}\crochs{C\pars{n, k, 0}}$ puisque $a = 0$}
    \frac{1}{n} \pars{C_{worst}\pars{n}} + \frac{n-1}{n} E_{k}\crochs{C\pars{n, k, 1}}
    \<=
    \commentaire{$C_{best}\pars{n} = E_{k}\crochs{C\pars{n, k, 1}}$ puisque $a = 1$}
    \frac{1}{n} \pars{C_{worst}\pars{n}} + \frac{n-1}{n} \pars{C_{best}\pars{n}}
    \<=
    \commentaire{Définition de $C_{worst}\pars{n}$}
    \frac{1}{n} \pars{\frac{2n^2-3n + 1}{6}} + \frac{n-1}{n} \pars{C_{best}\pars{n}}
    \<=
    \commentaire{Définition de $C_{best}\pars{n}$}
    \frac{1}{n} \pars{\frac{2n^2-3n + 1}{6}} + \frac{n-1}{n} \pars{0}
    \<=
    \commentaire{Simplification}
    \frac{1}{n} \pars{\frac{2n^2-3n + 1}{6}}
    \<=
    \commentaire{Simplification}
    \frac{2n^2-3n + 1}{6n}
\end{deriv}

\subsubsection*{Calcul de thêta}

Montrons que $C_{avg}\pars{n} \in \Theta\pars{n}$. 

Nous supposons que $C_{avg}\pars{n} \in \Theta\pars{n}$, car
le polynôme est un polynôme de degré 2 divisé par un polynôme de degré 1.

\begin{deriv}
    \lim\limits_{n->\infty} \frac{\frac{2n^2-3n + 1}{6n}}{n}
    \<=
    \commentaire{Double fraction}
    \lim\limits_{n->\infty} \frac{2n^2-3n + 1}{6n^2}
    \<=
    \commentaire{Règle de l'Hôspital}
    \lim\limits_{n->\infty} \frac{\pars{2n^2-3n + 1}'}{\pars{6n^2}'}
    \<=
    \commentaire{Distribuer la dérivée}
    \lim\limits_{n->\infty} \frac{\pars{2n^2}'-\pars{3n}' + \pars{1}'}{\pars{6n^2}'}
    \<=
    \commentaire{Dériver}
    \lim\limits_{n->\infty} \frac{2\cdot2n-1\cdot3 + 0\cdot1}{2\cdot6n}
    \<=
    \commentaire{Simplifier}
    \lim\limits_{n->\infty} \frac{4n-3}{12n}
    \<=
    \commentaire{Règle de l'Hôspital}
    \lim\limits_{n->\infty} \frac{\pars{4n-3}'}{\pars{12n}'}
    \<=
    \commentaire{Distribuer la dérivée}
    \lim\limits_{n->\infty} \frac{\pars{4n}'-\pars{3}'}{\pars{12n}'}
    \<=
    \commentaire{Dériver}
    \lim\limits_{n->\infty} \frac{1 \cdot 4-0 \cdot 3}{1 \cdot 12}
    \<=
    \commentaire{Simplifier}
    \lim\limits_{n->\infty} \frac{4}{12}
    \<=
    \commentaire{Résoudre la limite}
    \frac{4}{24}
    \<=
    \commentaire{Simplifier}
    \frac{1}{3}
\end{deriv}

Donc $C_{avg}\pars{n} \in \Theta\pars{n}$.

\end{document} 
